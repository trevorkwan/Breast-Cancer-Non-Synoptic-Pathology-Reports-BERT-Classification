{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier Summary\n",
    "\n",
    "- For example, classify Invasive Carcinoma given a qa_answer.\n",
    "- p(Present | qa_answer) = p(Present)* p(word_1 | Present) * p(word_2 | Present)...\n",
    "- Take the max of p(Present | qa_answer) and p(Absent | qa_answer) and classify it.\n",
    "- prior probability: p(Present) = # of Present rows in Invasive Carcinoma / # of total rows in Invasive Carcinoma\n",
    "- likelihoods: p(word_1 | Present) = # of rows with word_1 in Present and Invasive Carcinoma / # of total rows in Present and Invasive Carcinoma\n",
    "- OR if word_1 doesn't exist in training data, p(word_1 | Present) = 1/1000000\n",
    "- prior and liklihoods are based off the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>label_key</th>\n",
       "      <th>label_value</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td># of Sentinel LN</td>\n",
       "      <td>1254</td>\n",
       "      <td>1255</td>\n",
       "      <td># of Sentinel LN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the Number of Sentinel Nodes Examined?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td># of Sentinel LN</td>\n",
       "      <td>1344</td>\n",
       "      <td>1345</td>\n",
       "      <td># of Sentinel LN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the Number of Sentinel Nodes Examined?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Estimated Size of Largest LN</td>\n",
       "      <td>3924</td>\n",
       "      <td>3931</td>\n",
       "      <td>Estimated Size of Largest LN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the Estimated Size of Largest Lymph no...</td>\n",
       "      <td>0.5 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Histologic Type (Insitu) - Other</td>\n",
       "      <td>914</td>\n",
       "      <td>946</td>\n",
       "      <td>Histologic Type (Insitu)</td>\n",
       "      <td>Other</td>\n",
       "      <td>What is the In Situ Component Type?</td>\n",
       "      <td>encapsulated papillary carcinoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Estimated Size (IO)</td>\n",
       "      <td>957</td>\n",
       "      <td>962</td>\n",
       "      <td>Estimated Size</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the estimated size corresponding to an...</td>\n",
       "      <td>32 mm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>565</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Architectural Patterns (ID) - cribriform</td>\n",
       "      <td>1986</td>\n",
       "      <td>1997</td>\n",
       "      <td>Architectural Patterns (ID)</td>\n",
       "      <td>cribriform</td>\n",
       "      <td>What are the architectural patterns correspond...</td>\n",
       "      <td>cribriform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>565</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Architectural Patterns (ID) - solid</td>\n",
       "      <td>2001</td>\n",
       "      <td>2007</td>\n",
       "      <td>Architectural Patterns (ID)</td>\n",
       "      <td>solid</td>\n",
       "      <td>What are the architectural patterns correspond...</td>\n",
       "      <td>solid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4205</th>\n",
       "      <td>565</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Necrosis (ID) - Present</td>\n",
       "      <td>2469</td>\n",
       "      <td>2499</td>\n",
       "      <td>Necrosis</td>\n",
       "      <td>Present</td>\n",
       "      <td>What is the necrosis?</td>\n",
       "      <td>with comedonecrosis identified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4206</th>\n",
       "      <td>565</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Comedo necrosis</td>\n",
       "      <td>2474</td>\n",
       "      <td>2489</td>\n",
       "      <td>Comedo Necrosis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the necrosis type?</td>\n",
       "      <td>comedonecrosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>565</td>\n",
       "      <td>\\n                                       AGE/S...</td>\n",
       "      <td>Estimated Size of Largest LN</td>\n",
       "      <td>5710</td>\n",
       "      <td>5728</td>\n",
       "      <td>Estimated Size of Largest LN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What is the Estimated Size of Largest Lymph no...</td>\n",
       "      <td>1.6 x 0.4 x 0.3 cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4208 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_id                                               text  \\\n",
       "0             2  \\n                                       AGE/S...   \n",
       "1             2  \\n                                       AGE/S...   \n",
       "2             2  \\n                                       AGE/S...   \n",
       "3             2  \\n                                       AGE/S...   \n",
       "4             2  \\n                                       AGE/S...   \n",
       "...         ...                                                ...   \n",
       "4203        565  \\n                                       AGE/S...   \n",
       "4204        565  \\n                                       AGE/S...   \n",
       "4205        565  \\n                                       AGE/S...   \n",
       "4206        565  \\n                                       AGE/S...   \n",
       "4207        565  \\n                                       AGE/S...   \n",
       "\n",
       "                                         label  start   end  \\\n",
       "0                             # of Sentinel LN   1254  1255   \n",
       "1                             # of Sentinel LN   1344  1345   \n",
       "2                 Estimated Size of Largest LN   3924  3931   \n",
       "3             Histologic Type (Insitu) - Other    914   946   \n",
       "4                          Estimated Size (IO)    957   962   \n",
       "...                                        ...    ...   ...   \n",
       "4203  Architectural Patterns (ID) - cribriform   1986  1997   \n",
       "4204       Architectural Patterns (ID) - solid   2001  2007   \n",
       "4205                   Necrosis (ID) - Present   2469  2499   \n",
       "4206                           Comedo necrosis   2474  2489   \n",
       "4207              Estimated Size of Largest LN   5710  5728   \n",
       "\n",
       "                         label_key label_value  \\\n",
       "0                 # of Sentinel LN         NaN   \n",
       "1                 # of Sentinel LN         NaN   \n",
       "2     Estimated Size of Largest LN         NaN   \n",
       "3         Histologic Type (Insitu)       Other   \n",
       "4                   Estimated Size         NaN   \n",
       "...                            ...         ...   \n",
       "4203   Architectural Patterns (ID)  cribriform   \n",
       "4204   Architectural Patterns (ID)       solid   \n",
       "4205                      Necrosis     Present   \n",
       "4206               Comedo Necrosis         NaN   \n",
       "4207  Estimated Size of Largest LN         NaN   \n",
       "\n",
       "                                               question  \\\n",
       "0        What is the Number of Sentinel Nodes Examined?   \n",
       "1        What is the Number of Sentinel Nodes Examined?   \n",
       "2     What is the Estimated Size of Largest Lymph no...   \n",
       "3                   What is the In Situ Component Type?   \n",
       "4     What is the estimated size corresponding to an...   \n",
       "...                                                 ...   \n",
       "4203  What are the architectural patterns correspond...   \n",
       "4204  What are the architectural patterns correspond...   \n",
       "4205                              What is the necrosis?   \n",
       "4206                         What is the necrosis type?   \n",
       "4207  What is the Estimated Size of Largest Lymph no...   \n",
       "\n",
       "                                answer  \n",
       "0                                    1  \n",
       "1                                    1  \n",
       "2                               0.5 cm  \n",
       "3     encapsulated papillary carcinoma  \n",
       "4                                32 mm  \n",
       "...                                ...  \n",
       "4203                       cribriform   \n",
       "4204                            solid   \n",
       "4205    with comedonecrosis identified  \n",
       "4206                   comedonecrosis   \n",
       "4207                1.6 x 0.4 x 0.3 cm  \n",
       "\n",
       "[4208 rows x 9 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('../data/clean/non_synoptic/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\trevor.kwan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer\n",
    "\n",
    "def calculate_likelihood(train_df, desired_label_keys):\n",
    "    \"\"\"\n",
    "    For each label_key and label_value combination pair, get the likelihood prob of all words in it. e.g. p(word | Present)\n",
    "    \"\"\"\n",
    "    # Initialize the results list (to be converted to a DataFrame)\n",
    "    likelihoods = []\n",
    "\n",
    "    # For a given label_key\n",
    "    for label_key in desired_label_keys:\n",
    "        # Filter the DataFrame by the current label_key\n",
    "        filtered_df = train_df[train_df['label_key'] == label_key]\n",
    "\n",
    "        # Get the unique label values for this label key\n",
    "        unique_label_values = filtered_df['label_value'].unique()\n",
    "\n",
    "        # For a given label_key and label_value pair...\n",
    "        for label_value in unique_label_values:\n",
    "            # Get the label_key and label_value subset df\n",
    "            value_filtered_df = filtered_df[filtered_df['label_value'] == label_value]\n",
    "\n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            tokenized_sentences = value_filtered_df['answer'].apply(lambda x: [word.lower() for word in tokenizer.tokenize(x)])\n",
    "            # Breaks each answer in the subset df into words e.g. [negative, identifed] [positive, yes]...\n",
    "            # tokenized_sentences = value_filtered_df['answer'].apply(lambda x: [word.lower() for word in nltk.word_tokenize(x)])\n",
    "\n",
    "            # Gets the counts of each word in terms of how many times a word shows up in an answer and stores it in \"count\"\n",
    "            word_counts = Counter(word for words in tokenized_sentences for word in set(words))\n",
    "\n",
    "            # Get the number of rows in the label_key and label_value combination pair subset dataframe\n",
    "            total_rows = len(value_filtered_df)\n",
    "\n",
    "            # Calculate the probability of each word and add it to the likelihoods list\n",
    "            for word, count in word_counts.items():\n",
    "                likelihoods.append({\n",
    "                    'label_key': label_key,\n",
    "                    'label_value': label_value,\n",
    "                    'word': word,\n",
    "                    'prob': count / total_rows\n",
    "                })\n",
    "\n",
    "    # Convert the list to a DataFrame\n",
    "    return pd.DataFrame(likelihoods)\n",
    "\n",
    "desired_label_keys = [\"DCIS Margins\", \"ER Status\", \"Extranodal Extension\", \"HER2 Status\", \"Insitu Component\", \"Invasive Carcinoma\", \"Invasive Carcinoma Margins\", \"Lymphovascular Invasion\", \"Necrosis\", \"PR Status\", \"Tumour Focality\"]\n",
    "\n",
    "likelihood_df = calculate_likelihood(train_df, desired_label_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_key</th>\n",
       "      <th>label_value</th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>margins</td>\n",
       "      <td>0.595890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.746575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>free</td>\n",
       "      <td>0.109589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>all</td>\n",
       "      <td>0.246575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>of</td>\n",
       "      <td>0.178082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>invasive</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>a</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>is</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>tumour</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>698 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label_key label_value      word      prob\n",
       "0       DCIS Margins    Negative   margins  0.595890\n",
       "1       DCIS Margins    Negative  negative  0.746575\n",
       "2       DCIS Margins    Negative      free  0.109589\n",
       "3       DCIS Margins    Negative       all  0.246575\n",
       "4       DCIS Margins    Negative        of  0.178082\n",
       "..               ...         ...       ...       ...\n",
       "693  Tumour Focality      Single  invasive  0.057143\n",
       "694  Tumour Focality      Single         1  0.028571\n",
       "695  Tumour Focality      Single         a  0.028571\n",
       "696  Tumour Focality      Single        is  0.028571\n",
       "697  Tumour Focality      Single    tumour  0.028571\n",
       "\n",
       "[698 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_key</th>\n",
       "      <th>label_value</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Can't Be Assessed</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.912500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCIS Margins</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.081250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ER Status</td>\n",
       "      <td>Can't Be Assessed</td>\n",
       "      <td>0.014706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ER Status</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.191176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ER Status</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.794118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Extranodal Extension</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extranodal Extension</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HER2 Status</td>\n",
       "      <td>equivocal</td>\n",
       "      <td>0.081967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HER2 Status</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HER2 Status</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.196721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Insitu Component</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Insitu Component</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.853659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Invasive Carcinoma</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.179245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Invasive Carcinoma</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Invasive Carcinoma Margins</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.851190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Invasive Carcinoma Margins</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.148810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Lymphovascular Invasion</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lymphovascular Invasion</td>\n",
       "      <td>Cannot be determined</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lymphovascular Invasion</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.236364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Necrosis</td>\n",
       "      <td>Absent</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Necrosis</td>\n",
       "      <td>Present</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PR Status</td>\n",
       "      <td>Can't Be Assessed</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PR Status</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.293103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PR Status</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>0.477612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Tumour Focality</td>\n",
       "      <td>Single</td>\n",
       "      <td>0.522388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     label_key           label_value      prob\n",
       "0                 DCIS Margins     Can't Be Assessed  0.006250\n",
       "1                 DCIS Margins              Negative  0.912500\n",
       "2                 DCIS Margins              Positive  0.081250\n",
       "3                    ER Status     Can't Be Assessed  0.014706\n",
       "4                    ER Status              negative  0.191176\n",
       "5                    ER Status              positive  0.794118\n",
       "6         Extranodal Extension                Absent  0.478261\n",
       "7         Extranodal Extension               Present  0.521739\n",
       "8                  HER2 Status             equivocal  0.081967\n",
       "9                  HER2 Status              negative  0.721311\n",
       "10                 HER2 Status              positive  0.196721\n",
       "11            Insitu Component                Absent  0.146341\n",
       "12            Insitu Component               Present  0.853659\n",
       "13          Invasive Carcinoma                Absent  0.179245\n",
       "14          Invasive Carcinoma               Present  0.820755\n",
       "15  Invasive Carcinoma Margins              Negative  0.851190\n",
       "16  Invasive Carcinoma Margins              Positive  0.148810\n",
       "17     Lymphovascular Invasion                Absent  0.757576\n",
       "18     Lymphovascular Invasion  Cannot be determined  0.006061\n",
       "19     Lymphovascular Invasion               Present  0.236364\n",
       "20                    Necrosis                Absent  0.352941\n",
       "21                    Necrosis               Present  0.647059\n",
       "22                   PR Status     Can't Be Assessed  0.017241\n",
       "23                   PR Status              negative  0.293103\n",
       "24                   PR Status              positive  0.689655\n",
       "25             Tumour Focality              Multiple  0.477612\n",
       "26             Tumour Focality                Single  0.522388"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# Counting the occurrences for each combination of label_key and label_value\n",
    "occurrences = train_df[train_df['label_key'].isin(desired_label_keys)].groupby(['label_key', 'label_value']).size().reset_index(name='count')\n",
    "\n",
    "# Counting the total occurrences for each label_key\n",
    "total_occurrences = occurrences.groupby('label_key')['count'].transform('sum')\n",
    "\n",
    "# Calculating the probability\n",
    "occurrences['prob'] = occurrences['count'] / total_occurrences\n",
    "\n",
    "# Creating the prior_prob DataFrame with the desired columns\n",
    "prior_prob = occurrences[['label_key', 'label_value', 'prob']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "prior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "original_model_checkpoint = 'franklu/pubmed_bert_squadv2' # for qa\n",
    "original_model_name = original_model_checkpoint.split(\"/\")[-1]\n",
    "original_model_dir = \"../results/trained\\\\\"\n",
    "original_model_signature = '_19827_v2\\\\' # for qa\n",
    "version = \"v2\"\n",
    "\n",
    "foiset = [\"DCIS Margins\", \"ER Status\", \"Extranodal Extension\", \"HER2 Status\", \"Insitu Component\", \"Invasive Carcinoma\", \"Invasive Carcinoma Margins\", \"Lymphovascular Invasion\", \"Necrosis\", \"PR Status\", \"Tumour Focality\"]\n",
    "# foiset = [\"Invasive Carcinoma\"]\n",
    "\n",
    "def classify(qa_answer, label_key, likelihood_df, prior_prob, debug_file, train_df):\n",
    "    if pd.isna(qa_answer) or str(qa_answer).strip() == '':\n",
    "        return 'No Mention', {}\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    words = [word.lower() for word in tokenizer.tokenize(str(qa_answer))]\n",
    "    # words = [word.lower() for word in nltk.word_tokenize(str(qa_answer))]\n",
    "    debug_file.write(f\"Words in the qa_answer row: {words}\\n\")\n",
    "\n",
    "    product_likelihoods = {}\n",
    "\n",
    "    label_values = prior_prob[prior_prob['label_key'] == label_key]['label_value'].unique()\n",
    "    for label_value in label_values:\n",
    "        prior = prior_prob[(prior_prob['label_key'] == label_key) & (prior_prob['label_value'] == label_value)]['prob'].iloc[0]\n",
    "        debug_file.write(f\"The prior probs of this row: {prior}\\n\")\n",
    "\n",
    "        subset_count = train_df[(train_df['label_key'] == label_key) & (train_df['label_value'] == label_value)].shape[0]\n",
    "        debug_file.write(f\"The subset count is: {subset_count}\\n\")\n",
    "\n",
    "        for word in words:\n",
    "            entry = likelihood_df[(likelihood_df['label_key'] == label_key) & (likelihood_df['label_value'] == label_value) & (likelihood_df['word'].str.lower() == word)]\n",
    "            debug_file.write(f\"The entry is:{entry}\\n\")\n",
    "\n",
    "            # If the entry is empty, set the likelihood as 1 divided by the number of rows in the subset\n",
    "            if entry.empty:\n",
    "                likelihood = 1/1000000\n",
    "                debug_file.write(f\"likelihood = 1/1,000,000\\n\")\n",
    "                # likelihood = 1 / (subset_count + 1)\n",
    "                # debug_file.write(f\"likelihood = 1/(subset_count+1)\\n\")\n",
    "            else:\n",
    "                likelihood = entry['prob'].iloc[0]\n",
    "                debug_file.write(f\"likelihood = prob\\n\")\n",
    "\n",
    "            if label_value not in product_likelihoods:\n",
    "                product_likelihoods[label_value] = prior * likelihood\n",
    "            else:\n",
    "                product_likelihoods[label_value] *= likelihood\n",
    "\n",
    "            debug_file.write(f\"Midpoint product likelihood: {product_likelihoods}\\n\")\n",
    "\n",
    "    debug_file.write(f\"Final product likelihoods: {product_likelihoods}\\n\")\n",
    "\n",
    "    return (max(product_likelihoods, key=product_likelihoods.get) if product_likelihoods else 'No match', product_likelihoods)\n",
    "\n",
    "\n",
    "# Initialize a dictionary to hold the overall accuracies for each \"foi\"\n",
    "overall_accuracies = {}\n",
    "\n",
    "# Initialize a dictionary to hold the accuracies for each label_value for each \"foi\"\n",
    "label_value_accuracies = {}\n",
    "\n",
    "# Loop over each \"foi\" (label_key) in foiset\n",
    "for foi in foiset:\n",
    "    # create the bayes directory if it doesn't exist\n",
    "    base_directory = original_model_dir + original_model_name + original_model_signature + \"eval\\\\\" + version + \"\\\\\"\n",
    "    bayes_classification_directory = base_directory + foi + \"\\\\\" + \"bayes_classification\\\\\"\n",
    "    if not os.path.exists(bayes_classification_directory):\n",
    "        os.makedirs(bayes_classification_directory)\n",
    "    # create debug file\n",
    "    debug_filename = original_model_dir + original_model_name + original_model_signature + \"eval\\\\\" + version + \"\\\\\" + foi + \"\\\\\" + \"bayes_classification\\\\\" + \"debug_output.txt\"\n",
    "    with open(debug_filename, 'w') as debug_file:\n",
    "        # Load the prediction CSV\n",
    "        pred_foi = pd.read_csv(original_model_dir + original_model_name + original_model_signature + \"eval\\\\\" + version + \"\\\\\" + foi + \"\\\\\" + 'predictions_' + foi + '.csv')\n",
    "\n",
    "        # in val pred csvs, add No Mention\n",
    "        pred_foi['label_value'].fillna('No Mention', inplace=True)\n",
    "        pred_foi['label_value'].replace('', 'No Mention', inplace=True)\n",
    "\n",
    "        # Apply the classify function and store the results\n",
    "        # pred_foi['bayes_classification'] = pred_foi['qa_answer'].apply(lambda x: classify(x, foi, likelihood_df, prior_prob))\n",
    "\n",
    "        # Apply the classify function and store the results in two new columns\n",
    "        pred_foi['classification_results'] = pred_foi['qa_answer'].apply(lambda x: classify(x, foi, likelihood_df, prior_prob, debug_file, train_df))\n",
    "        pred_foi['bayes_classification'] = pred_foi['classification_results'].apply(lambda x: x[0])\n",
    "        pred_foi['prod_likelihoods'] = pred_foi['classification_results'].apply(lambda x: str(x[1]))  # Convert dictionary to string for saving\n",
    "\n",
    "        # Drop the temporary column used for storing both results\n",
    "        pred_foi.drop(columns=['classification_results'], inplace=True)\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        directory = original_model_dir + original_model_name + original_model_signature + \"eval\\\\\" + version + \"\\\\\" + foi + \"\\\\\" + \"bayes_classification\\\\\"\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "\n",
    "        # Save the new prediction CSV\n",
    "        pred_foi.to_csv(directory + 'pred_classified_' + foi + '.csv', index=False)\n",
    "\n",
    "        # Compute the overall accuracy for this \"foi\"\n",
    "        overall_accuracy = (pred_foi['bayes_classification'] == pred_foi['label_value']).mean()\n",
    "        overall_accuracies[foi] = overall_accuracy\n",
    "\n",
    "        # Compute the accuracy for each label_value for this \"foi\"\n",
    "        label_value_accuracy = pred_foi.groupby('label_value').apply(lambda df: (df['bayes_classification'] == df['label_value']).mean())\n",
    "        label_value_accuracies[foi] = label_value_accuracy\n",
    "\n",
    "        # Convert the label_value_accuracies to a DataFrame and save to a CSV file for this \"foi\"\n",
    "        label_value_accuracy_df = pd.DataFrame(label_value_accuracy, columns=['accuracy'])\n",
    "        label_value_accuracy_df.to_csv(directory + 'accuracies_' + foi + '.csv')\n",
    "\n",
    "# Convert the overall_accuracies to a DataFrame and save to a CSV file\n",
    "overall_accuracies_df = pd.DataFrame.from_dict(overall_accuracies, orient='index', columns=['accuracy'])\n",
    "\n",
    "# Convert the label_value_accuracies to a DataFrame and save to a CSV file\n",
    "label_value_accuracies_df = pd.concat({k: pd.Series(v) for k, v in label_value_accuracies.items()}).reset_index()\n",
    "label_value_accuracies_df.columns = ['foi', 'label_value', 'accuracy']\n",
    "\n",
    "# Append overall accuracies to label_value_accuracies_df\n",
    "overall_accuracies_df = overall_accuracies_df.reset_index().rename(columns={'index': 'foi', 'accuracy': 'accuracy'})\n",
    "combined_accuracies_df = pd.concat([label_value_accuracies_df, overall_accuracies_df], keys=['label_value_accuracy', 'overall_accuracy'], ignore_index=False)\n",
    "combined_accuracies_df.reset_index(level=0, inplace=True)\n",
    "combined_accuracies_df.rename(columns={'level_0': 'type'}, inplace=True)\n",
    "\n",
    "# Calculate the mean accuracy for \"No Mention\" across all FOIs\n",
    "no_mention_mean_accuracy = label_value_accuracies_df[label_value_accuracies_df['label_value'] == 'No Mention']['accuracy'].mean()\n",
    "# Create a DataFrame for the overall \"No Mention\" mean accuracy\n",
    "overall_no_mention_accuracy_df = pd.DataFrame({\n",
    "    'type': ['overall_accuracy'],\n",
    "    'foi': ['No Mention'],\n",
    "    'label_value': [None],\n",
    "    'accuracy': [no_mention_mean_accuracy]\n",
    "})\n",
    "# Concatenate the overall \"No Mention\" mean accuracy with the combined_accuracies_df\n",
    "combined_accuracies_df = pd.concat([combined_accuracies_df, overall_no_mention_accuracy_df], ignore_index=True)\n",
    "\n",
    "combined_accuracies_df.to_csv(original_model_dir + original_model_name + original_model_signature + 'eval\\\\' + version + \"\\\\\" + 'all_foi_bayes_accuracies.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trevor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
